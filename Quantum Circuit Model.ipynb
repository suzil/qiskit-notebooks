{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from collections import namedtuple\n",
    "from qiskit import QuantumCircuit, execute, Aer\n",
    "from qiskit.visualization import plot_histogram\n",
    "from enum import Enum, auto\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "Outcome = namedtuple(\"Outcome\", \"p00 p01 p10 p11\")\n",
    "Experiment = namedtuple(\"Experiment\", \"input_state outcome\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Design\n",
    "\n",
    "We will design a model that can predict the output probabilities given an input circuit design. Ideally, however, we could do the reverse problem: given a set of outcomes for all possible qubit inputs (00, 01, 10, 11), what is the circuit that creates it?\n",
    "\n",
    "In order to accomplish either of these tasks, however, we need some vector representation of a quantum circuit design to feed to our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: ('h', 0),\n",
       " 1: ('iden', 0),\n",
       " 2: ('u3', 0),\n",
       " 3: ('u2', 0),\n",
       " 4: ('u1', 0),\n",
       " 5: ('rx', 0),\n",
       " 6: ('ry', 0),\n",
       " 7: ('rz', 0),\n",
       " 8: ('x', 0),\n",
       " 9: ('y', 0),\n",
       " 10: ('z', 0),\n",
       " 11: ('s', 0),\n",
       " 12: ('sdg', 0),\n",
       " 13: ('t', 0),\n",
       " 14: ('tdg', 0),\n",
       " 15: ('h', 1),\n",
       " 16: ('iden', 1),\n",
       " 17: ('u3', 1),\n",
       " 18: ('u2', 1),\n",
       " 19: ('u1', 1),\n",
       " 20: ('rx', 1),\n",
       " 21: ('ry', 1),\n",
       " 22: ('rz', 1),\n",
       " 23: ('x', 1),\n",
       " 24: ('y', 1),\n",
       " 25: ('z', 1),\n",
       " 26: ('s', 1),\n",
       " 27: ('sdg', 1),\n",
       " 28: ('t', 1),\n",
       " 29: ('tdg', 1),\n",
       " 30: ('cx', 0, 1),\n",
       " 31: ('ch', 0, 1),\n",
       " 32: ('cy', 0, 1),\n",
       " 33: ('cz', 0, 1),\n",
       " 34: ('crz', 0, 1),\n",
       " 35: ('cu1', 0, 1),\n",
       " 36: ('cu3', 0, 1),\n",
       " 37: ('cx', 1, 0),\n",
       " 38: ('ch', 1, 0),\n",
       " 39: ('cy', 1, 0),\n",
       " 40: ('cz', 1, 0),\n",
       " 41: ('crz', 1, 0),\n",
       " 42: ('cu1', 1, 0),\n",
       " 43: ('cu3', 1, 0),\n",
       " 44: ('swap',)}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_qubit_gates = [\"h\", \"iden\", \"u3\", \"u2\", \"u1\", \"rx\", \"ry\", \"rz\", \"x\", \"y\", \"z\", \"s\", \"sdg\", \"t\", \"tdg\"]\n",
    "double_qubit_gates_directed = [\"cx\", \"ch\", \"cy\", \"cz\", \"crz\", \"cu1\", \"cu3\"]\n",
    "double_qubit_gates_undirected = [\"swap\"]\n",
    "\n",
    "idx2gate = {}\n",
    "idx = 0\n",
    "# Single qubit gates can be in the first qubit, in the second qubit, or in both qubits\n",
    "for qubit in (0, 1):\n",
    "    for gate in single_qubit_gates:\n",
    "        idx2gate[idx] = (gate, qubit)\n",
    "        idx += 1\n",
    "        \n",
    "# Double qubit gates that have a direction\n",
    "for control_qubit in (0, 1):\n",
    "    target_qubit = 1 if control_qubit == 0 else 0\n",
    "    for gate in double_qubit_gates_directed:\n",
    "        idx2gate[idx] = (gate, control_qubit, target_qubit)\n",
    "        idx += 1\n",
    "        \n",
    "# Double qubit gates without a direction\n",
    "for gate in double_qubit_gates_undirected:\n",
    "    idx2gate[idx] = (gate,)\n",
    "\n",
    "idx2gate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will represent our circuit as a 44x10 matrix, allowing for 10 steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose between the following choices:\n",
    "#   - single qubit gate at 0\n",
    "#   - single qubit gate at 1\n",
    "#   - single qubit gates at 0 and 1\n",
    "#   - double qubit gate with control at 0\n",
    "#   - double qubit gate with control at 1\n",
    "#   - undirected double qubit gate (swap)\n",
    "\n",
    "class GateOptions(Enum):\n",
    "    SINGLE_QUBIT_GATE_AT_0 = auto()\n",
    "    SINGLE_QUBIT_GATE_AT_1 = auto()\n",
    "    SINGLE_QUBIT_GATE_AT_BOTH = auto()\n",
    "    DOUBLE_QUBIT_GATE_WITH_CONTROL_AT_0 = auto()\n",
    "    DOUBLE_QUBIT_GATE_WITH_CONTROL_AT_1 = auto()\n",
    "    DOUBLE_QUBIT_GATE_UNDIRECTED = auto()\n",
    "    \n",
    "MAX_CIRCUIT_DEPTH = 10\n",
    "\n",
    "def generate_random_circuit_step(idx2gate):\n",
    "    step_vector = np.zeros(len(idx2gate))\n",
    "    gate_option = random.choice(list(GateOptions))\n",
    "    if gate_option == GateOptions.SINGLE_QUBIT_GATE_AT_0:\n",
    "        idx = random.choice(np.arange(len(single_qubit_gates)))\n",
    "        step_vector[idx] = 1\n",
    "\n",
    "    elif gate_option == GateOptions.SINGLE_QUBIT_GATE_AT_1:\n",
    "        idx = random.choice(np.arange(len(single_qubit_gates), len(single_qubit_gates) * 2))\n",
    "        step_vector[idx] = 1\n",
    "\n",
    "    elif gate_option == GateOptions.SINGLE_QUBIT_GATE_AT_BOTH:\n",
    "        idx = random.choice(np.arange(len(single_qubit_gates)))\n",
    "        step_vector[idx] = 1\n",
    "\n",
    "        idx = random.choice(np.arange(len(single_qubit_gates), len(single_qubit_gates) * 2))\n",
    "        step_vector[idx] = 1\n",
    "\n",
    "    elif gate_option == GateOptions.DOUBLE_QUBIT_GATE_WITH_CONTROL_AT_0:\n",
    "        start = len(single_qubit_gates) * 2\n",
    "        idx = random.choice(np.arange(start, start + len(double_qubit_gates_directed)))\n",
    "        step_vector[idx] = 1\n",
    "\n",
    "    elif gate_option == GateOptions.DOUBLE_QUBIT_GATE_WITH_CONTROL_AT_1:\n",
    "        start = len(single_qubit_gates) * 2 + len(double_qubit_gates_directed)\n",
    "        idx = random.choice(np.arange(start, start + len(double_qubit_gates_directed)))\n",
    "        step_vector[idx] = 1\n",
    "\n",
    "    elif gate_option == GateOptions.DOUBLE_QUBIT_GATE_UNDIRECTED:\n",
    "        start = len(single_qubit_gates) * 2 + len(double_qubit_gates_directed) * 2\n",
    "        idx = random.choice(np.arange(start, start + len(double_qubit_gates_undirected)))\n",
    "        step_vector[idx] = 1\n",
    "        \n",
    "    return step_vector\n",
    "\n",
    "def generate_random_circuit_matrix(idx2gate):\n",
    "    depth = random.choice(range(1, MAX_CIRCUIT_DEPTH + 1))\n",
    "    step_vectors = []\n",
    "    for _ in range(depth):\n",
    "        step_vector = generate_random_circuit_step(idx2gate)\n",
    "        step_vectors.append(step_vector)\n",
    "    # Add padding\n",
    "    step_vector_size = len(step_vectors[0])\n",
    "    padding_amount = MAX_CIRCUIT_DEPTH - depth\n",
    "    padding = padding_amount * [step_vector_size * [0]]\n",
    "    circuit_matrix = np.array(step_vectors + padding)\n",
    "    return circuit_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_outcomes(circuit_matrix, idx2gate):\n",
    "    \"\"\"Find the outcomes of all different qubit inputs.\n",
    "    \n",
    "    Qubit inputs are always in the ground state, so we have to\n",
    "    apply a SWITCH gate (x) in order to flip the Qubit to change\n",
    "    the input.\n",
    "    \"\"\"\n",
    "    experiments = []\n",
    "    \n",
    "    # 00\n",
    "    circuit_00 = QuantumCircuit(2, 2)\n",
    "    create_circuit_from_matrix(circuit_00, circuit_matrix, idx2gate)\n",
    "    experiment = Experiment(\"00\", run_simulation(circuit_00))\n",
    "    experiments.append(experiment)\n",
    "    \n",
    "    # 01\n",
    "    circuit_01 = QuantumCircuit(2, 2)\n",
    "    circuit_01.x(0)\n",
    "    create_circuit_from_matrix(circuit_01, circuit_matrix, idx2gate)\n",
    "    experiment = Experiment(\"01\", run_simulation(circuit_01))\n",
    "    experiments.append(experiment)\n",
    "    \n",
    "    # 10\n",
    "    circuit_10 = QuantumCircuit(2, 2)\n",
    "    circuit_10.x(1)\n",
    "    create_circuit_from_matrix(circuit_10, circuit_matrix, idx2gate)\n",
    "    experiment = Experiment(\"10\", run_simulation(circuit_10))\n",
    "    experiments.append(experiment)\n",
    "    \n",
    "    # 11\n",
    "    circuit_11 = QuantumCircuit(2, 2)\n",
    "    circuit_11.x(0)\n",
    "    circuit_11.x(1)\n",
    "    create_circuit_from_matrix(circuit_11, circuit_matrix, idx2gate)\n",
    "    experiment = Experiment(\"11\", run_simulation(circuit_11))\n",
    "    experiments.append(experiment)\n",
    "    \n",
    "    return circuit_00, experiments\n",
    "    \n",
    "def run_simulation(circuit, shots=2000):\n",
    "    circuit.measure([0,1], [0,1])\n",
    "    simulator = Aer.get_backend('qasm_simulator')\n",
    "    job = execute(circuit, simulator, shots=shots)\n",
    "    result = job.result()\n",
    "    counts = result.get_counts(circuit)\n",
    "    \n",
    "    p00 = counts.get(\"00\", 0) / shots\n",
    "    p01 = counts.get(\"01\", 0) / shots\n",
    "    p10 = counts.get(\"10\", 0) / shots\n",
    "    p11 = counts.get(\"11\", 0) / shots\n",
    "    \n",
    "    return Outcome(p00, p01, p10, p11)\n",
    "\n",
    "def create_circuit_from_matrix(circuit, circuit_matrix, idx2gate):\n",
    "    random_degree = lambda: 45  # random.random() * 360\n",
    "    for step_vector in circuit_matrix:\n",
    "        for gate_idx in np.where(step_vector == 1)[0]:\n",
    "            gate_name, *args = idx2gate[gate_idx]\n",
    "            gate_fn = eval(f\"circuit.{gate_name}\")\n",
    "            if not args:\n",
    "                # Double qubit gate undirected (swap)\n",
    "                gate_fn(0, 1)\n",
    "                \n",
    "            elif len(args) == 1:\n",
    "                # Single qubit gate\n",
    "                qubit = args[0]\n",
    "                if gate_name in {\"u1\", \"rx\", \"ry\"}:\n",
    "                    theta = random_degree()\n",
    "                    gate_fn(theta, qubit)\n",
    "                elif gate_name == \"u3\":\n",
    "                    theta = random_degree()\n",
    "                    phi = random_degree()\n",
    "                    lam = random_degree()\n",
    "                    gate_fn(theta, phi, lam, qubit)\n",
    "                elif gate_name == \"rz\":\n",
    "                    phi = random_degree()\n",
    "                    gate_fn(phi, qubit)\n",
    "                elif gate_name == \"u2\":\n",
    "                    lam = random_degree()\n",
    "                    phi = random_degree()\n",
    "                    gate_fn(phi, lam, qubit)\n",
    "                else:\n",
    "                    gate_fn(qubit)\n",
    "                \n",
    "            elif len(args) == 2:\n",
    "                # Double qubit gate\n",
    "                control, target = args\n",
    "                if gate_name in {\"cu1\", \"crz\"}:\n",
    "                    theta = random_degree()\n",
    "                    gate_fn(theta, control, target)\n",
    "                elif gate_name == \"cu3\":\n",
    "                    theta = random_degree()\n",
    "                    phi = random_degree()\n",
    "                    lam = random_degree()\n",
    "                    gate_fn(theta, phi, lam, control, target)\n",
    "                else:\n",
    "                    gate_fn(control, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea9d56ffa9514ae3b3a5d7935475ebfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Show example', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efc75a2dcb0242f9915d0e4c3e173bd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "button = widgets.Button(description=\"Show example\")\n",
    "output = widgets.Output()\n",
    "display(button, output)\n",
    "\n",
    "def show_generated_training_example(button):\n",
    "    circuit_matrix = generate_random_circuit_matrix(idx2gate)\n",
    "    circuit, experiments = find_outcomes(circuit_matrix, idx2gate)\n",
    "    with output:\n",
    "        clear_output(wait=True)\n",
    "        for experiment in experiments:\n",
    "            print(\"Input qubits:\", experiment.input_state)\n",
    "            print(\"Outcome:\")\n",
    "            outcome = experiment.outcome\n",
    "            print(f\"{outcome.p00:.2f}\\t{outcome.p01:.2f}\\t{outcome.p10:.2f}\\t{outcome.p11:.2f}\")\n",
    "            print()\n",
    "        display(circuit.draw(output=\"mpl\"))\n",
    "\n",
    "button.on_click(show_generated_training_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Examples(Dataset):\n",
    "    def __getitem__(self, _):\n",
    "        circuit_matrix = generate_random_circuit_matrix(idx2gate)\n",
    "        _, experiments = find_outcomes(circuit_matrix, idx2gate)\n",
    "        outcomes = [experiment.outcome for experiment in experiments]\n",
    "        outcomes = [[outcome.p00, outcome.p01, outcome.p10, outcome.p11] for outcome in outcomes]\n",
    "        flattened_outcomes = np.array([sublst for lst in outcomes for sublst in lst])\n",
    "        return circuit_matrix, flattened_outcomes\n",
    "    \n",
    "    def __len__(self):\n",
    "        # \"Infinite\" training examples\n",
    "        return int(1e10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Examples()\n",
    "BATCH_SIZE = 512\n",
    "train_loader = DataLoader(dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CircuitPredictor(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size,\n",
    "        output_size,\n",
    "        batch_size,\n",
    "        hidden_size=128, \n",
    "        n_layers=1,\n",
    "        device='cpu',\n",
    "    ):\n",
    "        super(CircuitPredictor, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.device = device\n",
    "        self.batch_size = batch_size\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        self.rnn = nn.GRU(\n",
    "            input_size,\n",
    "            hidden_size,\n",
    "            num_layers=n_layers,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.decoder = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def init_hidden(self):\n",
    "        return torch.randn(self.n_layers, self.batch_size, self.hidden_size).to(self.device)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        # Avoid breaking if the last batch has a different size\n",
    "        batch_size = inputs.size(0)\n",
    "        if batch_size != self.batch_size:\n",
    "            self.batch_size = batch_size\n",
    "\n",
    "        output, hidden = self.rnn(inputs.float(), self.init_hidden())\n",
    "        output = self.decoder(output[:, -1, :]).squeeze()\n",
    "        return F.sigmoid(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CircuitPredictor(\n",
       "  (rnn): GRU(45, 128, batch_first=True)\n",
       "  (decoder): Linear(in_features=128, out_features=16, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CircuitPredictor(len(idx2gate), 4 * 4, BATCH_SIZE)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam([p for p in model.parameters() if p.requires_grad], lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.160\n",
      "Loss: 0.155\n",
      "Loss: 0.161\n",
      "Loss: 0.158\n",
      "Loss: 0.158\n",
      "Loss: 0.151\n",
      "Loss: 0.148\n",
      "Loss: 0.146\n",
      "Loss: 0.145\n",
      "Loss: 0.140\n",
      "Loss: 0.137\n",
      "Loss: 0.141\n",
      "Loss: 0.135\n",
      "Loss: 0.122\n",
      "Loss: 0.119\n",
      "Loss: 0.115\n",
      "Loss: 0.107\n",
      "Loss: 0.101\n",
      "Loss: 0.094\n",
      "Loss: 0.095\n",
      "Loss: 0.096\n",
      "Loss: 0.102\n",
      "Loss: 0.101\n",
      "Loss: 0.097\n",
      "Loss: 0.099\n",
      "Loss: 0.101\n",
      "Loss: 0.097\n",
      "Loss: 0.096\n",
      "Loss: 0.093\n",
      "Loss: 0.090\n",
      "Loss: 0.092\n",
      "Loss: 0.089\n",
      "Loss: 0.090\n",
      "Loss: 0.094\n",
      "Loss: 0.092\n",
      "Loss: 0.092\n",
      "Loss: 0.089\n",
      "Loss: 0.092\n",
      "Loss: 0.088\n",
      "Loss: 0.091\n",
      "Loss: 0.089\n",
      "Loss: 0.094\n",
      "Loss: 0.089\n",
      "Loss: 0.093\n",
      "Loss: 0.084\n",
      "Loss: 0.088\n",
      "Loss: 0.088\n",
      "Loss: 0.091\n",
      "Loss: 0.094\n",
      "Loss: 0.088\n",
      "Loss: 0.090\n",
      "Loss: 0.089\n",
      "Loss: 0.093\n",
      "Loss: 0.093\n",
      "Loss: 0.085\n",
      "Loss: 0.090\n",
      "Loss: 0.085\n",
      "Loss: 0.091\n",
      "Loss: 0.095\n",
      "Loss: 0.088\n",
      "Loss: 0.091\n",
      "Loss: 0.091\n",
      "Loss: 0.084\n",
      "Loss: 0.092\n",
      "Loss: 0.087\n",
      "Loss: 0.097\n",
      "Loss: 0.088\n",
      "Loss: 0.091\n",
      "Loss: 0.089\n",
      "Loss: 0.088\n",
      "Loss: 0.091\n",
      "Loss: 0.088\n",
      "Loss: 0.091\n",
      "Loss: 0.088\n",
      "Loss: 0.091\n",
      "Loss: 0.088\n",
      "Loss: 0.088\n",
      "Loss: 0.084\n",
      "Loss: 0.091\n",
      "Loss: 0.091\n",
      "Loss: 0.087\n",
      "Loss: 0.088\n",
      "Loss: 0.092\n",
      "Loss: 0.090\n",
      "Loss: 0.089\n",
      "Loss: 0.092\n",
      "Loss: 0.088\n",
      "Loss: 0.090\n",
      "Loss: 0.086\n",
      "Loss: 0.087\n",
      "Loss: 0.089\n",
      "Loss: 0.090\n",
      "Loss: 0.090\n",
      "Loss: 0.088\n",
      "Loss: 0.087\n",
      "Loss: 0.090\n",
      "Loss: 0.093\n",
      "Loss: 0.087\n",
      "Loss: 0.087\n",
      "Loss: 0.087\n",
      "Loss: 0.089\n",
      "Loss: 0.087\n",
      "Loss: 0.091\n",
      "Loss: 0.084\n",
      "Loss: 0.085\n",
      "Loss: 0.085\n",
      "Loss: 0.088\n",
      "Loss: 0.092\n",
      "Loss: 0.084\n",
      "Loss: 0.085\n",
      "Loss: 0.093\n",
      "Loss: 0.087\n",
      "Loss: 0.092\n",
      "Loss: 0.091\n",
      "Loss: 0.086\n",
      "Loss: 0.084\n",
      "Loss: 0.087\n",
      "Loss: 0.090\n",
      "Loss: 0.092\n",
      "Loss: 0.087\n",
      "Loss: 0.090\n",
      "Loss: 0.087\n",
      "Loss: 0.086\n",
      "Loss: 0.087\n",
      "Loss: 0.088\n",
      "Loss: 0.087\n",
      "Loss: 0.086\n",
      "Loss: 0.086\n",
      "Loss: 0.088\n",
      "Loss: 0.084\n",
      "Loss: 0.091\n",
      "Loss: 0.088\n",
      "Loss: 0.090\n",
      "Loss: 0.091\n",
      "Loss: 0.090\n",
      "Loss: 0.094\n",
      "Loss: 0.089\n",
      "Loss: 0.089\n",
      "Loss: 0.088\n",
      "Loss: 0.087\n",
      "Loss: 0.084\n",
      "Loss: 0.085\n",
      "Loss: 0.087\n",
      "Loss: 0.088\n",
      "Loss: 0.087\n",
      "Loss: 0.086\n",
      "Loss: 0.094\n",
      "Loss: 0.090\n",
      "Loss: 0.086\n",
      "Loss: 0.086\n",
      "Loss: 0.086\n",
      "Loss: 0.089\n",
      "Loss: 0.087\n",
      "Loss: 0.087\n",
      "Loss: 0.087\n",
      "Loss: 0.090\n",
      "Loss: 0.090\n",
      "Loss: 0.080\n",
      "Loss: 0.084\n",
      "Loss: 0.086\n",
      "Loss: 0.082\n",
      "Loss: 0.082\n",
      "Loss: 0.083\n",
      "Loss: 0.085\n",
      "Loss: 0.084\n",
      "Loss: 0.087\n",
      "Loss: 0.086\n",
      "Loss: 0.086\n",
      "Loss: 0.087\n",
      "Loss: 0.084\n",
      "Loss: 0.082\n",
      "Loss: 0.081\n",
      "Loss: 0.082\n",
      "Loss: 0.083\n",
      "Loss: 0.083\n",
      "Loss: 0.081\n",
      "Loss: 0.088\n",
      "Loss: 0.082\n",
      "Loss: 0.079\n",
      "Loss: 0.082\n",
      "Loss: 0.083\n",
      "Loss: 0.084\n",
      "Loss: 0.082\n",
      "Loss: 0.083\n",
      "Loss: 0.084\n",
      "Loss: 0.083\n",
      "Loss: 0.086\n",
      "Loss: 0.080\n",
      "Loss: 0.086\n",
      "Loss: 0.079\n",
      "Loss: 0.084\n",
      "Loss: 0.083\n",
      "Loss: 0.086\n",
      "Loss: 0.080\n",
      "Loss: 0.084\n",
      "Loss: 0.078\n",
      "Loss: 0.083\n",
      "Loss: 0.082\n",
      "Loss: 0.080\n",
      "Loss: 0.083\n",
      "Loss: 0.081\n",
      "Loss: 0.082\n",
      "Loss: 0.078\n",
      "Loss: 0.081\n",
      "Loss: 0.080\n",
      "Loss: 0.086\n",
      "Loss: 0.083\n",
      "Loss: 0.079\n",
      "Loss: 0.086\n",
      "Loss: 0.084\n",
      "Loss: 0.082\n",
      "Loss: 0.079\n",
      "Loss: 0.079\n",
      "Loss: 0.080\n",
      "Loss: 0.086\n",
      "Loss: 0.079\n",
      "Loss: 0.078\n",
      "Loss: 0.081\n",
      "Loss: 0.081\n",
      "Loss: 0.077\n",
      "Loss: 0.081\n",
      "Loss: 0.081\n",
      "Loss: 0.082\n",
      "Loss: 0.080\n",
      "Loss: 0.081\n",
      "Loss: 0.085\n",
      "Loss: 0.081\n",
      "Loss: 0.078\n",
      "Loss: 0.079\n",
      "Loss: 0.077\n",
      "Loss: 0.083\n",
      "Loss: 0.076\n",
      "Loss: 0.080\n",
      "Loss: 0.082\n",
      "Loss: 0.085\n",
      "Loss: 0.081\n",
      "Loss: 0.079\n",
      "Loss: 0.080\n",
      "Loss: 0.078\n",
      "Loss: 0.081\n",
      "Loss: 0.079\n",
      "Loss: 0.080\n",
      "Loss: 0.081\n",
      "Loss: 0.080\n",
      "Loss: 0.080\n",
      "Loss: 0.081\n",
      "Loss: 0.076\n",
      "Loss: 0.076\n",
      "Loss: 0.080\n",
      "Loss: 0.083\n",
      "Loss: 0.078\n",
      "Loss: 0.075\n",
      "Loss: 0.076\n",
      "Loss: 0.076\n",
      "Loss: 0.083\n",
      "Loss: 0.083\n",
      "Loss: 0.078\n",
      "Loss: 0.075\n",
      "Loss: 0.081\n",
      "Loss: 0.073\n",
      "Loss: 0.081\n",
      "Loss: 0.073\n",
      "Loss: 0.076\n",
      "Loss: 0.080\n",
      "Loss: 0.082\n",
      "Loss: 0.077\n",
      "Loss: 0.076\n",
      "Loss: 0.083\n",
      "Loss: 0.077\n",
      "Loss: 0.082\n",
      "Loss: 0.077\n",
      "Loss: 0.076\n",
      "Loss: 0.080\n",
      "Loss: 0.077\n",
      "Loss: 0.079\n",
      "Loss: 0.080\n",
      "Loss: 0.076\n",
      "Loss: 0.074\n",
      "Loss: 0.077\n",
      "Loss: 0.078\n",
      "Loss: 0.075\n",
      "Loss: 0.075\n",
      "Loss: 0.078\n",
      "Loss: 0.080\n",
      "Loss: 0.081\n",
      "Loss: 0.075\n",
      "Loss: 0.078\n",
      "Loss: 0.074\n",
      "Loss: 0.077\n",
      "Loss: 0.081\n",
      "Loss: 0.078\n",
      "Loss: 0.074\n",
      "Loss: 0.074\n",
      "Loss: 0.073\n",
      "Loss: 0.071\n",
      "Loss: 0.074\n",
      "Loss: 0.073\n",
      "Loss: 0.078\n",
      "Loss: 0.078\n",
      "Loss: 0.080\n",
      "Loss: 0.081\n",
      "Loss: 0.075\n",
      "Loss: 0.082\n",
      "Loss: 0.074\n",
      "Loss: 0.076\n",
      "Loss: 0.077\n",
      "Loss: 0.078\n",
      "Loss: 0.076\n",
      "Loss: 0.077\n",
      "Loss: 0.076\n",
      "Loss: 0.077\n",
      "Loss: 0.078\n",
      "Loss: 0.078\n",
      "Loss: 0.073\n",
      "Loss: 0.077\n",
      "Loss: 0.076\n",
      "Loss: 0.072\n",
      "Loss: 0.076\n",
      "Loss: 0.076\n",
      "Loss: 0.075\n",
      "Loss: 0.075\n",
      "Loss: 0.076\n",
      "Loss: 0.077\n",
      "Loss: 0.072\n",
      "Loss: 0.073\n",
      "Loss: 0.075\n",
      "Loss: 0.077\n",
      "Loss: 0.078\n",
      "Loss: 0.073\n",
      "Loss: 0.074\n",
      "Loss: 0.076\n",
      "Loss: 0.078\n",
      "Loss: 0.074\n",
      "Loss: 0.073\n",
      "Loss: 0.075\n",
      "Loss: 0.074\n",
      "Loss: 0.079\n",
      "Loss: 0.075\n",
      "Loss: 0.075\n",
      "Loss: 0.076\n",
      "Loss: 0.073\n",
      "Loss: 0.075\n",
      "Loss: 0.074\n",
      "Loss: 0.074\n",
      "Loss: 0.074\n",
      "Loss: 0.073\n",
      "Loss: 0.074\n",
      "Loss: 0.073\n",
      "Loss: 0.074\n",
      "Loss: 0.076\n",
      "Loss: 0.071\n",
      "Loss: 0.077\n",
      "Loss: 0.074\n",
      "Loss: 0.075\n",
      "Loss: 0.073\n",
      "Loss: 0.075\n",
      "Loss: 0.073\n",
      "Loss: 0.075\n",
      "Loss: 0.074\n",
      "Loss: 0.075\n",
      "Loss: 0.069\n",
      "Loss: 0.081\n",
      "Loss: 0.072\n",
      "Loss: 0.074\n",
      "Loss: 0.075\n",
      "Loss: 0.075\n",
      "Loss: 0.074\n",
      "Loss: 0.076\n",
      "Loss: 0.075\n",
      "Loss: 0.075\n",
      "Loss: 0.075\n",
      "Loss: 0.075\n",
      "Loss: 0.071\n",
      "Loss: 0.077\n",
      "Loss: 0.073\n",
      "Loss: 0.073\n",
      "Loss: 0.074\n",
      "Loss: 0.076\n",
      "Loss: 0.074\n",
      "Loss: 0.075\n",
      "Loss: 0.076\n",
      "Loss: 0.074\n",
      "Loss: 0.076\n",
      "Loss: 0.071\n",
      "Loss: 0.071\n",
      "Loss: 0.077\n",
      "Loss: 0.074\n",
      "Loss: 0.075\n",
      "Loss: 0.072\n",
      "Loss: 0.079\n",
      "Loss: 0.072\n",
      "Loss: 0.073\n",
      "Loss: 0.077\n",
      "Loss: 0.070\n",
      "Loss: 0.070\n",
      "Loss: 0.078\n",
      "Loss: 0.073\n",
      "Loss: 0.072\n",
      "Loss: 0.070\n",
      "Loss: 0.073\n",
      "Loss: 0.077\n",
      "Loss: 0.073\n",
      "Loss: 0.073\n",
      "Loss: 0.075\n",
      "Loss: 0.072\n",
      "Loss: 0.074\n",
      "Loss: 0.071\n",
      "Loss: 0.075\n",
      "Loss: 0.077\n",
      "Loss: 0.075\n",
      "Loss: 0.073\n",
      "Loss: 0.070\n",
      "Loss: 0.072\n",
      "Loss: 0.075\n",
      "Loss: 0.074\n",
      "Loss: 0.074\n",
      "Loss: 0.071\n",
      "Loss: 0.074\n",
      "Loss: 0.073\n",
      "Loss: 0.075\n",
      "Loss: 0.070\n",
      "Loss: 0.077\n",
      "Loss: 0.072\n",
      "Loss: 0.075\n",
      "Loss: 0.073\n",
      "Loss: 0.070\n",
      "Loss: 0.071\n",
      "Loss: 0.073\n",
      "Loss: 0.075\n",
      "Loss: 0.071\n",
      "Loss: 0.074\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-370-86f0fda593a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcircuit_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutcomes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcircuit_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutcomes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/qiskit/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/qiskit/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/qiskit/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-365-fbacbcbfec61>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, _)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mcircuit_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_random_circuit_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx2gate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_outcomes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcircuit_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx2gate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0moutcomes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutcome\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mexperiment\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexperiments\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0moutcomes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moutcome\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp00\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutcome\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutcome\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutcome\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp11\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0moutcome\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutcomes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-363-6f40cdb80197>\u001b[0m in \u001b[0;36mfind_outcomes\u001b[0;34m(circuit_matrix, idx2gate)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mcircuit_11\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mcircuit_11\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mcreate_circuit_from_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcircuit_11\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcircuit_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx2gate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0mexperiment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExperiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"11\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_simulation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcircuit_11\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mexperiments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-363-6f40cdb80197>\u001b[0m in \u001b[0;36mcreate_circuit_from_matrix\u001b[0;34m(circuit, circuit_matrix, idx2gate)\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mgate_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_vector\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0mgate_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midx2gate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgate_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             \u001b[0mgate_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"circuit.{gate_name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m                 \u001b[0;31m# Double qubit gate undirected (swap)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<string>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "for i, (circuit_matrix, outcomes) in enumerate(train_loader, 1):\n",
    "    model.zero_grad()\n",
    "    output = model(circuit_matrix)\n",
    "    loss = criterion(output, outcomes.float())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    print(f\"Loss: {loss.item():.3f}\")\n",
    "    \n",
    "    losses.append(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
